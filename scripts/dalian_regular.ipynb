{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csi/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:  1.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" \n",
    "Usage:\n",
    "    THEANO_FLAGS=\"device=gpu0\" python exptBasestationXIAN.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from deepst.models.STResNet import stresnet\n",
    "from deepst.config import Config\n",
    "import deepst.metrics as metrics\n",
    "from deepst.datasets import DalianRegular\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "# parameters\n",
    "# data path, you may set your own data path with the global envirmental\n",
    "# variable DATAPATH\n",
    "DATAPATH = Config().DATAPATH\n",
    "nb_epoch = 500  # number of epoch at training stage\n",
    "nb_epoch_cont = 100  # number of epoch at training (cont) stage\n",
    "batch_size = 32  # batch size\n",
    "T = 48  # number of time intervals in one day\n",
    "nbfilter=64\n",
    "lr = 0.0002  # learning rate\n",
    "len_closeness = 3  # length of closeness dependent sequence\n",
    "len_period = 0  # length of peroid dependent sequence\n",
    "len_trend = 0  # length of trend dependent sequence\n",
    "nb_residual_unit = 4   # number of residual units\n",
    "\n",
    "nb_flow = 2  # there are two types of flows: new-flow and end-flow\n",
    "# divide data into two subsets: Train & Test, of which the test set is the\n",
    "# last 10 days\n",
    "days_test = 4\n",
    "len_test = T * days_test\n",
    "map_height, map_width = 8, 8  # grid size\n",
    "# For NYC Bike data, there are 81 available grid-based areas, each of\n",
    "# which includes at least ONE bike station. Therefore, we modify the final\n",
    "# RMSE by multiplying the following factor (i.e., factor).\n",
    "nb_area = 8 * 8\n",
    "m_factor = math.sqrt(1. * map_height * map_width / nb_area)\n",
    "print('factor: ', m_factor)\n",
    "path_result = 'RET'\n",
    "path_model = 'MODEL'\n",
    "\n",
    "if os.path.isdir(path_result) is False:\n",
    "    os.mkdir(path_result)\n",
    "if os.path.isdir(path_model) is False:\n",
    "    os.mkdir(path_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "incomplete days:  []\n",
      "train_data shape:  (1152, 2, 8, 8)\n",
      "min: 0.0 max: 2881.0\n",
      "XC shape:  (1341, 6, 8, 8) XP shape:  (0,) XT shape:  (0,) Y shape: (1341, 2, 8, 8)\n",
      "XC shape:  (1341, 6, 8, 8) XP shape:  (1, 0) XT shape:  (1, 0) Y shape: (1341, 2, 8, 8)\n",
      "train shape: (1149, 6, 8, 8) (1149, 2, 8, 8) test shape:  (192, 6, 8, 8) (192, 2, 8, 8)\n",
      "(1149, 6, 8, 8)\n",
      "\n",
      "(192, 6, 8, 8)\n",
      "\n",
      "\n",
      " days (test):  [b'20150113', b'20150114', b'20150115', b'20150116']\n",
      "==========\n",
      "compiling model...\n",
      "**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\n",
      "before build_model\n",
      "external_dim: None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 6, 8, 8)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 8, 8)      3520        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 64, 8, 8)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 8, 8)      36928       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 64, 8, 8)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 8, 8)      36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 64, 8, 8)      0           convolution2d_1[0][0]            \n",
      "                                                                   convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 64, 8, 8)      0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 8, 8)      36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 64, 8, 8)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 64, 8, 8)      36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 64, 8, 8)      0           merge_1[0][0]                    \n",
      "                                                                   convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 64, 8, 8)      0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 64, 8, 8)      36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 64, 8, 8)      0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 64, 8, 8)      36928       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 64, 8, 8)      0           merge_2[0][0]                    \n",
      "                                                                   convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 64, 8, 8)      0           merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 64, 8, 8)      36928       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 64, 8, 8)      0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 64, 8, 8)      36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 64, 8, 8)      0           merge_3[0][0]                    \n",
      "                                                                   convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 64, 8, 8)      0           merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 2, 8, 8)       1154        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 2, 8, 8)       0           convolution2d_10[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 300,098\n",
      "Trainable params: 300,098\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "after build_model\n",
      "==========\n",
      "training model...\n",
      "Train on 984 samples, validate on 165 samples\n",
      "Epoch 1/500\n",
      "2s - loss: 0.0012 - rmse: 0.0304 - val_loss: 4.4439e-04 - val_rmse: 0.0208\n",
      "Epoch 2/500\n",
      "0s - loss: 3.3002e-04 - rmse: 0.0179 - val_loss: 3.5743e-04 - val_rmse: 0.0187\n",
      "Epoch 3/500\n",
      "0s - loss: 2.8028e-04 - rmse: 0.0164 - val_loss: 3.1980e-04 - val_rmse: 0.0176\n",
      "Epoch 4/500\n",
      "0s - loss: 2.4061e-04 - rmse: 0.0153 - val_loss: 3.0777e-04 - val_rmse: 0.0172\n",
      "Epoch 5/500\n",
      "0s - loss: 2.2713e-04 - rmse: 0.0148 - val_loss: 2.7897e-04 - val_rmse: 0.0164\n",
      "Epoch 6/500\n",
      "0s - loss: 2.0677e-04 - rmse: 0.0142 - val_loss: 2.8778e-04 - val_rmse: 0.0167\n",
      "Epoch 7/500\n",
      "0s - loss: 1.9543e-04 - rmse: 0.0137 - val_loss: 2.7888e-04 - val_rmse: 0.0164\n",
      "Epoch 8/500\n",
      "0s - loss: 1.9701e-04 - rmse: 0.0138 - val_loss: 2.7369e-04 - val_rmse: 0.0163\n",
      "Epoch 9/500\n",
      "0s - loss: 1.9010e-04 - rmse: 0.0136 - val_loss: 2.6266e-04 - val_rmse: 0.0159\n",
      "Epoch 10/500\n",
      "0s - loss: 1.8551e-04 - rmse: 0.0134 - val_loss: 2.4398e-04 - val_rmse: 0.0153\n",
      "Epoch 11/500\n",
      "0s - loss: 1.8190e-04 - rmse: 0.0132 - val_loss: 2.5490e-04 - val_rmse: 0.0156\n",
      "Epoch 12/500\n",
      "0s - loss: 1.7341e-04 - rmse: 0.0130 - val_loss: 2.3757e-04 - val_rmse: 0.0151\n",
      "Epoch 13/500\n",
      "0s - loss: 1.6832e-04 - rmse: 0.0127 - val_loss: 2.4061e-04 - val_rmse: 0.0152\n",
      "Epoch 14/500\n",
      "0s - loss: 1.6790e-04 - rmse: 0.0127 - val_loss: 2.3044e-04 - val_rmse: 0.0148\n",
      "Epoch 15/500\n",
      "0s - loss: 1.7492e-04 - rmse: 0.0130 - val_loss: 2.3862e-04 - val_rmse: 0.0151\n",
      "Epoch 16/500\n",
      "0s - loss: 1.7091e-04 - rmse: 0.0129 - val_loss: 2.3725e-04 - val_rmse: 0.0150\n",
      "Epoch 17/500\n",
      "0s - loss: 1.6848e-04 - rmse: 0.0128 - val_loss: 2.5366e-04 - val_rmse: 0.0156\n",
      "Epoch 18/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 1.6783e-04 - rmse: 0.0127 - val_loss: 2.3765e-04 - val_rmse: 0.0150\n",
      "Epoch 19/500\n",
      "0s - loss: 1.6126e-04 - rmse: 0.0124 - val_loss: 2.7358e-04 - val_rmse: 0.0162\n",
      "Epoch 20/500\n",
      "0s - loss: 1.7085e-04 - rmse: 0.0128 - val_loss: 2.3599e-04 - val_rmse: 0.0150\n",
      "==========\n",
      "evaluating using the model that has the best loss on the valid set\n",
      "Train score: 0.000169 rmse (norm): 0.012220 rmse (real): 35.206894\n",
      "Test score: 0.000299 rmse (norm): 0.017306 rmse (real): 49.857888\n",
      "==========\n",
      "training model (cont)...\n",
      "Train on 1149 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.8395e-04 - rmse: 0.0133 - val_loss: 3.0488e-04 - val_rmse: 0.0172\n",
      "Epoch 2/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.7661e-04 - rmse: 0.0131 - val_loss: 3.2128e-04 - val_rmse: 0.0177\n",
      "Epoch 3/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.8019e-04 - rmse: 0.0131 - val_loss: 3.0036e-04 - val_rmse: 0.0170\n",
      "Epoch 4/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.7795e-04 - rmse: 0.0131 - val_loss: 3.2415e-04 - val_rmse: 0.0177\n",
      "Epoch 5/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.7587e-04 - rmse: 0.0130 - val_loss: 3.3562e-04 - val_rmse: 0.0180\n",
      "Epoch 6/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.7307e-04 - rmse: 0.0129 - val_loss: 2.9762e-04 - val_rmse: 0.0169\n",
      "Epoch 7/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.7802e-04 - rmse: 0.0130 - val_loss: 3.0211e-04 - val_rmse: 0.0171\n",
      "Epoch 8/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.8857e-04 - rmse: 0.0135 - val_loss: 3.2180e-04 - val_rmse: 0.0176\n",
      "Epoch 9/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.6972e-04 - rmse: 0.0128 - val_loss: 3.0431e-04 - val_rmse: 0.0171\n",
      "Epoch 10/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.8128e-04 - rmse: 0.0131 - val_loss: 3.1347e-04 - val_rmse: 0.0174\n",
      "Epoch 11/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.6173e-04 - rmse: 0.0125 - val_loss: 3.4625e-04 - val_rmse: 0.0183\n",
      "Epoch 12/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.8105e-04 - rmse: 0.0132 - val_loss: 2.9484e-04 - val_rmse: 0.0169\n",
      "Epoch 13/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.6528e-04 - rmse: 0.0126 - val_loss: 3.1249e-04 - val_rmse: 0.0174\n",
      "Epoch 14/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5989e-04 - rmse: 0.0124 - val_loss: 3.1658e-04 - val_rmse: 0.0174\n",
      "Epoch 15/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5750e-04 - rmse: 0.0123 - val_loss: 2.9627e-04 - val_rmse: 0.0168\n",
      "Epoch 16/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5180e-04 - rmse: 0.0121 - val_loss: 2.8769e-04 - val_rmse: 0.0166\n",
      "Epoch 17/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5968e-04 - rmse: 0.0124 - val_loss: 3.0237e-04 - val_rmse: 0.0170\n",
      "Epoch 18/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5040e-04 - rmse: 0.0120 - val_loss: 2.8234e-04 - val_rmse: 0.0165\n",
      "Epoch 19/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5170e-04 - rmse: 0.0122 - val_loss: 2.9251e-04 - val_rmse: 0.0167\n",
      "Epoch 20/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4941e-04 - rmse: 0.0121 - val_loss: 2.8249e-04 - val_rmse: 0.0164\n",
      "Epoch 21/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4855e-04 - rmse: 0.0119 - val_loss: 3.3261e-04 - val_rmse: 0.0179\n",
      "Epoch 22/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.6239e-04 - rmse: 0.0125 - val_loss: 3.0791e-04 - val_rmse: 0.0172\n",
      "Epoch 23/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4961e-04 - rmse: 0.0120 - val_loss: 2.7891e-04 - val_rmse: 0.0164\n",
      "Epoch 24/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4395e-04 - rmse: 0.0118 - val_loss: 2.8103e-04 - val_rmse: 0.0164\n",
      "Epoch 25/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4350e-04 - rmse: 0.0117 - val_loss: 2.8463e-04 - val_rmse: 0.0165\n",
      "Epoch 26/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4406e-04 - rmse: 0.0117 - val_loss: 2.9276e-04 - val_rmse: 0.0167\n",
      "Epoch 27/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4393e-04 - rmse: 0.0118 - val_loss: 3.0268e-04 - val_rmse: 0.0170\n",
      "Epoch 28/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.4144e-04 - rmse: 0.0116 - val_loss: 3.2264e-04 - val_rmse: 0.0175\n",
      "Epoch 29/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5379e-04 - rmse: 0.0121 - val_loss: 2.8802e-04 - val_rmse: 0.0167\n",
      "Epoch 30/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4146e-04 - rmse: 0.0117 - val_loss: 2.8292e-04 - val_rmse: 0.0165\n",
      "Epoch 31/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4458e-04 - rmse: 0.0118 - val_loss: 2.7541e-04 - val_rmse: 0.0163\n",
      "Epoch 32/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3905e-04 - rmse: 0.0116 - val_loss: 2.8500e-04 - val_rmse: 0.0165\n",
      "Epoch 33/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4424e-04 - rmse: 0.0118 - val_loss: 2.8287e-04 - val_rmse: 0.0164\n",
      "Epoch 34/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4094e-04 - rmse: 0.0116 - val_loss: 2.8024e-04 - val_rmse: 0.0164\n",
      "Epoch 35/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3826e-04 - rmse: 0.0116 - val_loss: 2.8545e-04 - val_rmse: 0.0165\n",
      "Epoch 36/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4419e-04 - rmse: 0.0118 - val_loss: 3.0493e-04 - val_rmse: 0.0170\n",
      "Epoch 37/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.3796e-04 - rmse: 0.0115 - val_loss: 2.7908e-04 - val_rmse: 0.0164\n",
      "Epoch 38/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4034e-04 - rmse: 0.0115 - val_loss: 2.9302e-04 - val_rmse: 0.0168\n",
      "Epoch 39/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3477e-04 - rmse: 0.0112 - val_loss: 2.7459e-04 - val_rmse: 0.0162\n",
      "Epoch 40/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4045e-04 - rmse: 0.0116 - val_loss: 3.1500e-04 - val_rmse: 0.0173\n",
      "Epoch 41/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3467e-04 - rmse: 0.0114 - val_loss: 2.6782e-04 - val_rmse: 0.0161\n",
      "Epoch 42/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3723e-04 - rmse: 0.0115 - val_loss: 2.9001e-04 - val_rmse: 0.0166\n",
      "Epoch 43/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3651e-04 - rmse: 0.0114 - val_loss: 2.9055e-04 - val_rmse: 0.0167\n",
      "Epoch 44/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3575e-04 - rmse: 0.0114 - val_loss: 3.0831e-04 - val_rmse: 0.0172\n",
      "Epoch 45/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4313e-04 - rmse: 0.0118 - val_loss: 3.8226e-04 - val_rmse: 0.0192\n",
      "Epoch 46/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4647e-04 - rmse: 0.0119 - val_loss: 2.8670e-04 - val_rmse: 0.0166\n",
      "Epoch 47/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3267e-04 - rmse: 0.0114 - val_loss: 2.7514e-04 - val_rmse: 0.0162\n",
      "Epoch 48/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3958e-04 - rmse: 0.0114 - val_loss: 2.6440e-04 - val_rmse: 0.0160\n",
      "Epoch 49/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3278e-04 - rmse: 0.0113 - val_loss: 2.8730e-04 - val_rmse: 0.0165\n",
      "Epoch 50/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4010e-04 - rmse: 0.0116 - val_loss: 3.1885e-04 - val_rmse: 0.0174\n",
      "Epoch 51/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3860e-04 - rmse: 0.0115 - val_loss: 2.8030e-04 - val_rmse: 0.0164\n",
      "Epoch 52/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.4236e-04 - rmse: 0.0117 - val_loss: 2.8972e-04 - val_rmse: 0.0166\n",
      "Epoch 53/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3449e-04 - rmse: 0.0114 - val_loss: 2.7598e-04 - val_rmse: 0.0163\n",
      "Epoch 54/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2934e-04 - rmse: 0.0111 - val_loss: 2.9560e-04 - val_rmse: 0.0168\n",
      "Epoch 55/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3844e-04 - rmse: 0.0115 - val_loss: 3.1171e-04 - val_rmse: 0.0172\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149/1149 [==============================] - 0s - loss: 1.3015e-04 - rmse: 0.0112 - val_loss: 3.0507e-04 - val_rmse: 0.0171\n",
      "Epoch 57/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2340e-04 - rmse: 0.0109 - val_loss: 3.1242e-04 - val_rmse: 0.0172\n",
      "Epoch 58/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2792e-04 - rmse: 0.0111 - val_loss: 2.7754e-04 - val_rmse: 0.0163\n",
      "Epoch 59/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2878e-04 - rmse: 0.0111 - val_loss: 2.9364e-04 - val_rmse: 0.0167\n",
      "Epoch 60/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2231e-04 - rmse: 0.0109 - val_loss: 2.6731e-04 - val_rmse: 0.0160\n",
      "Epoch 61/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1669e-04 - rmse: 0.0106 - val_loss: 2.8455e-04 - val_rmse: 0.0165\n",
      "Epoch 62/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.5561e-04 - rmse: 0.0122 - val_loss: 2.8971e-04 - val_rmse: 0.0167\n",
      "Epoch 63/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2591e-04 - rmse: 0.0111 - val_loss: 3.2158e-04 - val_rmse: 0.0175\n",
      "Epoch 64/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2165e-04 - rmse: 0.0109 - val_loss: 2.8315e-04 - val_rmse: 0.0164\n",
      "Epoch 65/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.3690e-04 - rmse: 0.0114 - val_loss: 2.9689e-04 - val_rmse: 0.0168\n",
      "Epoch 66/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2827e-04 - rmse: 0.0111 - val_loss: 3.3791e-04 - val_rmse: 0.0180\n",
      "Epoch 67/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1903e-04 - rmse: 0.0107 - val_loss: 3.1140e-04 - val_rmse: 0.0172\n",
      "Epoch 68/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.1788e-04 - rmse: 0.0106 - val_loss: 2.7363e-04 - val_rmse: 0.0162\n",
      "Epoch 69/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.1732e-04 - rmse: 0.0106 - val_loss: 2.6429e-04 - val_rmse: 0.0159\n",
      "Epoch 70/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.1528e-04 - rmse: 0.0105 - val_loss: 2.8215e-04 - val_rmse: 0.0164\n",
      "Epoch 71/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1525e-04 - rmse: 0.0105 - val_loss: 2.7847e-04 - val_rmse: 0.0163\n",
      "Epoch 72/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1803e-04 - rmse: 0.0106 - val_loss: 2.7364e-04 - val_rmse: 0.0162\n",
      "Epoch 73/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.2240e-04 - rmse: 0.0108 - val_loss: 2.8124e-04 - val_rmse: 0.0164\n",
      "Epoch 74/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.3020e-04 - rmse: 0.0113 - val_loss: 2.7130e-04 - val_rmse: 0.0161\n",
      "Epoch 75/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.1110e-04 - rmse: 0.0103 - val_loss: 2.8363e-04 - val_rmse: 0.0164\n",
      "Epoch 76/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.1259e-04 - rmse: 0.0104 - val_loss: 2.8332e-04 - val_rmse: 0.0165\n",
      "Epoch 77/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1346e-04 - rmse: 0.0105 - val_loss: 2.8790e-04 - val_rmse: 0.0166\n",
      "Epoch 78/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0549e-04 - rmse: 0.0101 - val_loss: 2.9198e-04 - val_rmse: 0.0167\n",
      "Epoch 79/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0367e-04 - rmse: 0.0100 - val_loss: 2.8457e-04 - val_rmse: 0.0164\n",
      "Epoch 80/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.1124e-04 - rmse: 0.0103 - val_loss: 2.9377e-04 - val_rmse: 0.0168\n",
      "Epoch 81/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1001e-04 - rmse: 0.0103 - val_loss: 2.7358e-04 - val_rmse: 0.0162\n",
      "Epoch 82/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.1502e-04 - rmse: 0.0105 - val_loss: 3.0781e-04 - val_rmse: 0.0171\n",
      "Epoch 83/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0389e-04 - rmse: 0.0100 - val_loss: 2.7090e-04 - val_rmse: 0.0160\n",
      "Epoch 84/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0424e-04 - rmse: 0.0100 - val_loss: 2.7473e-04 - val_rmse: 0.0163\n",
      "Epoch 85/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0277e-04 - rmse: 0.0099 - val_loss: 3.3884e-04 - val_rmse: 0.0179\n",
      "Epoch 86/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.0988e-04 - rmse: 0.0103 - val_loss: 2.7239e-04 - val_rmse: 0.0162\n",
      "Epoch 87/100\n",
      "1149/1149 [==============================] - 1s - loss: 9.6515e-05 - rmse: 0.0097 - val_loss: 2.9665e-04 - val_rmse: 0.0168\n",
      "Epoch 88/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0171e-04 - rmse: 0.0099 - val_loss: 3.1314e-04 - val_rmse: 0.0172\n",
      "Epoch 89/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0187e-04 - rmse: 0.0099 - val_loss: 2.7148e-04 - val_rmse: 0.0161\n",
      "Epoch 90/100\n",
      "1149/1149 [==============================] - 0s - loss: 9.5505e-05 - rmse: 0.0096 - val_loss: 2.9388e-04 - val_rmse: 0.0168\n",
      "Epoch 91/100\n",
      "1149/1149 [==============================] - 1s - loss: 9.7511e-05 - rmse: 0.0097 - val_loss: 2.7936e-04 - val_rmse: 0.0163\n",
      "Epoch 92/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0107e-04 - rmse: 0.0099 - val_loss: 3.0663e-04 - val_rmse: 0.0171\n",
      "Epoch 93/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0280e-04 - rmse: 0.0100 - val_loss: 2.8266e-04 - val_rmse: 0.0164\n",
      "Epoch 94/100\n",
      "1149/1149 [==============================] - 0s - loss: 1.0420e-04 - rmse: 0.0099 - val_loss: 2.6109e-04 - val_rmse: 0.0158\n",
      "Epoch 95/100\n",
      "1149/1149 [==============================] - 1s - loss: 9.5204e-05 - rmse: 0.0095 - val_loss: 2.6910e-04 - val_rmse: 0.0161\n",
      "Epoch 96/100\n",
      "1149/1149 [==============================] - 1s - loss: 1.0315e-04 - rmse: 0.0100 - val_loss: 3.0279e-04 - val_rmse: 0.0170\n",
      "Epoch 97/100\n",
      "1149/1149 [==============================] - 1s - loss: 9.4815e-05 - rmse: 0.0096 - val_loss: 3.0098e-04 - val_rmse: 0.0170\n",
      "Epoch 98/100\n",
      "1149/1149 [==============================] - 1s - loss: 9.4957e-05 - rmse: 0.0096 - val_loss: 3.1854e-04 - val_rmse: 0.0175\n",
      "Epoch 99/100\n",
      "1149/1149 [==============================] - 0s - loss: 9.4996e-05 - rmse: 0.0095 - val_loss: 3.5619e-04 - val_rmse: 0.0184\n",
      "Epoch 100/100\n",
      "1149/1149 [==============================] - 1s - loss: 9.2383e-05 - rmse: 0.0094 - val_loss: 2.8792e-04 - val_rmse: 0.0165\n",
      "==========\n",
      "evaluating using the final model\n",
      "Train score: 0.000079 rmse (norm): 0.008431 rmse (real): 24.290968\n",
      "Test score: 0.000288 rmse (norm): 0.016968 rmse (real): 48.885266\n"
     ]
    }
   ],
   "source": [
    "def build_model(external_dim, nbfilter=64):\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "    p_conf = (len_period, nb_flow, map_height,\n",
    "              map_width) if len_period > 0 else None\n",
    "    t_conf = (len_trend, nb_flow, map_height,\n",
    "              map_width) if len_trend > 0 else None\n",
    "\n",
    "    model = stresnet(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n",
    "                     external_dim=external_dim, nb_residual_unit=nb_residual_unit, nbfilter=nbfilter)\n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n",
    "    model.summary()\n",
    "    # from keras.utils.visualize_util import plot\n",
    "    # plot(model, to_file='model.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load data\n",
    "    print(\"loading data...\")\n",
    "    X_train, Y_train, X_test, Y_test, mmn, external_dim, timestamp_train, timestamp_test = DalianRegular.load_data(\n",
    "        T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n",
    "        preprocess_name='preprocessing.pkl', meta_data=False)\n",
    "\n",
    "    print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"compiling model...\")\n",
    "    print(\n",
    "        \"**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\")\n",
    "    print(\"before build_model\")\n",
    "    model = build_model(external_dim, nbfilter=nbfilter)\n",
    "    print(\"after build_model\")\n",
    "    hyperparams_name = 'c{}.p{}.t{}.resunit{}.lr{}'.format(\n",
    "        len_closeness, len_period, len_trend, nb_residual_unit, lr)\n",
    "    fname_param = os.path.join('MODEL', '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_rmse', patience=5, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"training model...\")\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.143,\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        verbose=2)\n",
    "    model.save_weights(os.path.join(\n",
    "        'MODEL', '{}.h5'.format(hyperparams_name)), overwrite=True)\n",
    "    pickle.dump((history.history), open(os.path.join(\n",
    "        path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "\n",
    "    print('=' * 10)\n",
    "    print('evaluating using the model that has the best loss on the valid set')\n",
    "\n",
    "    model.load_weights(fname_param)\n",
    "    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                           0] // 48, verbose=0)\n",
    "    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) * m_factor))\n",
    "\n",
    "    score = model.evaluate(\n",
    "        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) * m_factor))\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"training model (cont)...\")\n",
    "    fname_param = os.path.join(\n",
    "        'MODEL', '{}.cont.best.h5'.format(hyperparams_name))\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        fname_param, monitor='rmse', verbose=0, save_best_only=True, mode='min')\n",
    "    history = model.fit(X_train, Y_train, nb_epoch=nb_epoch_cont, verbose=1, batch_size=batch_size, callbacks=[\n",
    "                        model_checkpoint], validation_data=(X_test, Y_test))\n",
    "    pickle.dump((history.history), open(os.path.join(\n",
    "        path_result, '{}.cont.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "    model.save_weights(os.path.join(\n",
    "        'MODEL', '{}_cont.h5'.format(hyperparams_name)), overwrite=True)\n",
    "\n",
    "    print('=' * 10)\n",
    "    print('evaluating using the final model')\n",
    "     \n",
    "    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                           0] // 48, verbose=0)\n",
    "    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) * m_factor))\n",
    "\n",
    "    score2 = model.predict(X_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    file_temp = h5py.File(\"prediction\", \"w\")\n",
    "    file_temp.create_dataset(\"prediction\", data=score2)\n",
    "    file_temp.create_dataset(\"real\", data=Y_test)\n",
    "    score = model.evaluate(\n",
    "        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) * m_factor))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
